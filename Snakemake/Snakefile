import pandas as pd 
import os



from glob import glob
from io import StringIO

import pysam

sarscov2_genelist_initial = "assets/2697049_genelist.csv"


genelist_df = pd.read_csv(sarscov2_genelist_initial).set_index("gene", drop=False)


if "genes" in config:
	gene_list = config["genes"].split(",")
else:
	gene_list = genelist_df.gene.values


genelist_df = genelist_df[genelist_df.gene.isin(gene_list)]

genelist_df.to_csv("assets/2697049_genelist_filtered.csv",index=False)

print(genelist_df)

sarscov2_genelist = "assets/2697049_genelist_filtered.csv"




def cliquesnv_coords(genelist, genename, sample):
	
	gene = genelist.loc[genename,]

	start, end = gene.start, gene.end

	# Dumb thing with cliquesnv if the specified boundaries have less then 3 depth
	# So we check the minimum/max positions that have coverage and adjust 
	# the start/stop positions accordingly

	bam = "output/haplotype/{sample}/{gene}.bam".format(gene=genename, sample=sample)
	
	command_str = " -sp {start} -ep {end} -os {start} -oe {end} ".format(start=start-1, end=end-1)
	
	return command_str

def get_genes(wildcards):
	checkpoints.getgenebam.get(**wildcards).output

	haplotype_info = pd.read_csv("output/haplotype/{sample}/{sample}_haplotype_info.txt".format(sample=wildcards.sample))
	#haplotype_info[haplotype_info["pass"] == True]
	haplotype_info = haplotype_info[haplotype_info.reads > 50]
	
	gene = haplotype_info.gene.values
        return gene	

def get_input(inputdir):
	
	bam_files = glob("%s/*.bam"%inputdir)
	basenames = list(map(os.path.basename, bam_files))
	
	bam_files_ref = pd.Series(bam_files, index=basenames)
	delim_df = pd.DataFrame.from_records([(basename, basename.count("_"),) for basename in basenames], columns=["basename","delim_count"])
		
	out_df_list = []
	
	for c, df in delim_df.groupby("delim_count"):
		if c == 0:
			out_df_list.append(pd.DataFrame(dict(samplename=df.basename.apply(lambda x:x.replace(".bam","")).values,
							     fielname=bam_files_ref[df.basename.values].values)))
			continue

		for i in range(c):
			s = pd.Series(map(lambda x:"_".join(x.split("_")[:(i+1)]), df.basename))
			if len(s.drop_duplicates()) == len(s):
				out_df_list.append(pd.DataFrame(dict(samplename=s.values, filename=bam_files_ref[df.basename.values].values)))
				break

			



	return pd.concat(out_df_list).set_index("samplename",drop=False)
	#return pd.DataFrame(dict(samplename=s.values, filename=bam_files)).set_index("samplename",drop=False)





sample_df = get_input(config["inputdir"])

sample_df.to_csv("./sampledf.csv")

rule all:
	input:
		agg_csv="output/mutation_table_aggregate.csv"
	output:
		"output/done.txt"
	shell:
		'find output -name "*.bam" -exec rm {{}} \; ; touch {output}'



rule dedupbam:
	input:
		bam=lambda wildcards: sample_df.loc[wildcards.sample,].filename,
		bai=lambda wildcards: "{bam}.bai".format(bam=sample_df.loc[wildcards.sample,].filename)
		
	output:
		BAM=temporary("output/bam.dedup/{sample}.bam"),
		M="output/dedup.metrics/{sample}.txt"

	shell:
		"picard MarkDuplicates I={input.bam} O={output.BAM} M={output.M}"
	

rule lofreqviterbi:
	input:
		bam="output/bam.dedup/{sample}.bam"
	output:
		bam="output/bam.dedup/{sample}.viterbi.bam"
	shell:
		"lofreq viterbi -f assets/NC_045512.3.fasta {input.bam} | samtools sort -o {output} && "
		"samtools index {output}"  

checkpoint getgenebam:
	input:
		#bam=lambda wildcards: sample_df.loc[wildcards.sample,].filename,
		#bai=lambda wildcards: "{bam}.bai".format(bam=sample_df.loc[wildcards.sample,].filename)
		bam="output/bam.dedup/{sample}.viterbi.bam"

	output:
		haplotype_info="output/haplotype/{sample}/{sample}_haplotype_info.txt",
	params:
		genelist=sarscov2_genelist,
		output_dir="output/haplotype/{sample}/"
	shell:
		"python3 scripts/cliquesnvhaplo.py -p {wildcards.sample}  -b {input.bam} -g {params.genelist} -o {params.output_dir}  "


rule getgenebam_agg:
	input:
		lambda wildcards: expand("output/haplotype/{{sample}}/{gene}", gene=get_genes(wildcards))

	output:
		"output/{sample}_haplotypes.txt"
	shell:
		"touch {output}"


rule getgenebam_mark:
	input:
		bam="output/haplotype/{sample}/{gene}.bam"
	output:
		bam=temporary("output/haplotype/{sample}/{gene}.bam")
	shell:
		"touch {output.bam}"


rule subsample_genebam:
        input:
                bam="output/haplotype/{sample}/{gene}.bam"
        output:
                bam=temporary("output/haplotype/{sample}/{gene}.downsample.bam")

        params: 
                max_depth=1000

        shell: 
                "java -jar tools/sortsamrefname.jar {input.bam} 2> /dev/zero | java -jar tools/biostar154220.jar -n {params.max_depth} 2> /dev/zero | samtools sort - > {output.bam}"



rule cliquesnv:
	input:
		gene_bam="output/haplotype/{sample}/{gene}.downsample.bam",
		gene_orig_bam="output/haplotype/{sample}/{gene}.bam"
		#gene_bam=rules.subsample_genebam.output.bam
	output:
		cliquesnv="output/haplotype/{sample}/{gene}.downsample.fasta"
	params:
		clique_coord = lambda wildcards: cliquesnv_coords(genelist_df, wildcards.gene, wildcards.sample),
		outdir = lambda wildcards: "output/haplotype/{sample}/".format(sample=wildcards.sample),
	threads: 4
	resources: 
		mem=10
	shell:
		"java -Xmx8G -jar tools/clique-snv.jar {params.clique_coord} -tf 0.01 -m snv-illumina -in {input.gene_bam} -outDir {params.outdir} -threads {threads} > /dev/zero && rm {input.gene_orig_bam}"

rule cliquesnvparse:
	input:
		rules.cliquesnv.output
	output:
		cliquesnv="output/haplotype/{sample}/{gene}.fasta"
	shell:
		"python3 scripts/parsecliquesnv.py -m 12 -i {input} -n {wildcards.sample} -o {output.cliquesnv}"



rule cliquesnv_agg:
	input:
		lambda wildcards: expand("output/haplotype/{{sample}}/{gene}.fasta", sample=wildcards.sample, gene=get_genes(wildcards))
	output:
		"output/{sample}_cliquesnvagg.txt"
	shell:
		"touch {output}"

rule virulign:
	input:
		"output/haplotype/{sample}/{gene}.fasta"

	output:
		"output/virulign/{gene}/{sample}.csv"
	
	threads: 4
	resources: 
		mem=10
	shell:
		"virulign assets/virulign/{wildcards.gene}.xml {input} --exportReferenceSequence yes --exportKind PositionTable --exportAlphabet AminoAcids > {output}"


rule virulign_process:
	input:
		rules.virulign.output
	output:
		mut_table="output/mutation_tables/{sample}_{gene}.csv",
		agg_table="output/agg_aatables/{sample}_{gene}.csv",
		normal_table="output/aatables/{sample}_{gene}.csv"
	shell:
		"python3 scripts/virulignparse.py -i {input} -m {output.mut_table} -a {output.agg_table} -n {output.normal_table}"


rule virulign_agg:
	input:
		samp=lambda wildcards: expand("output/virulign/{gene}/{sample}.csv", sample=wildcards.sample, gene=get_genes(wildcards)),
		genes=lambda wildcards: expand("output/mutation_tables/{sample}_{gene}.csv", sample=wildcards.sample, gene=get_genes(wildcards)) 
	

		

	output:
		virulign=temporary("output/{sample}_virulign.txt"),
		agg_csv="output/mutation_tables_agg/{sample}_mutation_table_aggregate.csv"
		
	params:
		agg_csv="output/{sample}_mutation_table_aggregate.csv"
		
	
	run:
		shell("touch {output.virulign}")
		print("Input:",input.keys())
		if "genes" in input.keys():
			print("genes in output")
			shell("touch {output.virulign}")
				
			shell("python3 scripts/aggregate.py -c {input.genes} -o {output.agg_csv}")
		else:
			print("genes NOT in output")
			shell("touch {output.agg_csv}")


rule muttable_agg:
	input:
		expand("output/mutation_tables_agg/{sample}_mutation_table_aggregate.csv", sample=sample_df.samplename)
	output:
		"output/mutation_table_aggregate.csv"
	shell:
		"python scripts/aggregate.py -c {input} -o {output}"



